{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c2f2bf51",
   "metadata": {},
   "source": [
    "Q5. Use Naive bayes, K-nearest, and Decision tree classification algorithms and build classifiers. Divide the data set into training and test set. Compare the accuracy of the different classifiers under the following situations:\n",
    " 5.1 a) Training set = 75% Test set = 25%\n",
    " b) Training set = 66.6% (2/3rd of total), Test set = 33.3% \n",
    "\n",
    "5.2 Training set is chosen by\n",
    " i) hold out method ii) Random subsampling iii) Cross-Validation. Compare the accuracy of the classifiers obtained.\n",
    "\n",
    "5.3 Data is scaled to standard format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06520552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score,cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "df1 = pd.read_csv('diabetes.csv')\n",
    "df2 = pd.read_csv('Thyroid_Diff.csv')\n",
    "\n",
    "df1.info()\n",
    "\n",
    "df2.info()\n",
    "\n",
    "list_for_onehot = ['Thyroid Function','Physical Examination','Adenopathy','Pathology',\n",
    "                   'Pathology','Risk','T','N','Stage','Response']\n",
    "\n",
    "# binary categorical --> to --> binary numerical\n",
    "\n",
    "df2['Gender'] = (df2['Gender']=='M').astype(int)\n",
    "df2['Smoking'] = (df2['Smoking']=='Yes').astype(int)\n",
    "df2['Hx Smoking'] = (df2['Hx Smoking']=='Yes').astype(int)\n",
    "df2['Hx Radiothreapy'] = (df2['Hx Radiothreapy']=='Yes').astype(int)\n",
    "df2['Focality'] = (df2['Focality']=='Uni-Focal').astype(int)\n",
    "df2['M'] = (df2['M']=='M1').astype(int)\n",
    "df2['Recurred'] = (df2['Recurred']=='Yes').astype(int)\n",
    "\n",
    "df2 = pd.get_dummies(df2, columns = list_for_onehot)\n",
    "df2.info()\n",
    "\n",
    "tf_map = {False:0, True:1}\n",
    "\n",
    "cols_to_encode = [x for x in range(8,54)]\n",
    "\n",
    "for col_idx in cols_to_encode:\n",
    "    df2.iloc[:, col_idx] = df2.iloc[:, col_idx].map(tf_map)\n",
    "\n",
    "df2.info()\n",
    "\n",
    "X1 = df1.loc[:,df1.columns!='Outcome']\n",
    "y1 = df1.loc[:,'Outcome']\n",
    "\n",
    "X2 = df2.loc[:,df2.columns!='Recurred']\n",
    "y2 = df2.loc[:,'Recurred']\n",
    "\n",
    "# a) 75%-25%\n",
    "X1_train_A, X1_test_A, y1_train_A, y1_test_A = train_test_split(X1, y1, test_size=0.25, random_state=42)\n",
    "X2_train_A, X2_test_A, y2_train_A, y2_test_A = train_test_split(X2, y2, test_size=0.25, random_state=42)\n",
    "\n",
    "# b) 66.6%-33.3%\n",
    "X1_train_B, X1_test_B, y1_train_B, y1_test_B = train_test_split(X1, y1, test_size=0.33, random_state=42)\n",
    "X2_train_B, X2_test_B, y2_train_B, y2_test_B = train_test_split(X2, y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1 Evaluation on Train-Test Split as 75-25 and 66.6-33.3\n",
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "print('For DF1: 75% Train - 25% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X1_train_A, y1_train_A)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X1_test_A)\n",
    "    accuracy = accuracy_score(y1_test_A, y_pred)\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nFor DF1: 66.6% Train - 33.3% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X1_train_B, y1_train_B)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X1_test_B)\n",
    "    accuracy = accuracy_score(y1_test_B, y_pred)\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nFor DF2: 75% Train - 25% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X2_train_A, y2_train_A)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X2_test_A)\n",
    "    accuracy = accuracy_score(y2_test_A, y_pred)\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nFor DF2: 66.6% Train - 33.3% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X2_train_B, y2_train_B)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X2_test_B)\n",
    "    accuracy = accuracy_score(y2_test_B, y_pred)\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27368483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2 Evaluation using Holdout, Random Subsampling and 5-Fold CV\n",
    "\n",
    "# a) holdout (70%-30%)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, stratify=y1, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, stratify=y2, random_state=42)\n",
    "\n",
    "print('Holdout Method for DF1: 70% Train - 30% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X1_test)\n",
    "    accuracy = accuracy_score(y1_test, y_pred)\n",
    "    print('  ',f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nHoldout Method for DF2: 70% Train - 30% Test')\n",
    "for name, clf in classifiers.items():\n",
    "\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X2_train, y2_train)\n",
    "\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X2_test)\n",
    "    accuracy = accuracy_score(y2_test, y_pred)\n",
    "    print('  ',f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "\n",
    "# b) random subsample \n",
    "\n",
    "X1_train_1, X1_test_1, y1_train_1, y1_test_1 = train_test_split(X1, y1, test_size=0.2, random_state=42)  # 80-20\n",
    "X1_train_2, X1_test_2, y1_train_2, y1_test_2 = train_test_split(X1, y1, test_size=0.33, random_state=42)  # 66.6-33.3\n",
    "X1_train_3, X1_test_3, y1_train_3, y1_test_3 = train_test_split(X1, y1, test_size=0.3, random_state=42)  # 70-30\n",
    "\n",
    "X2_train_1, X2_test_1, y2_train_1, y2_test_1 = train_test_split(X2, y2, test_size=0.2, random_state=42)  # 80-20\n",
    "X2_train_2, X2_test_2, y2_train_2, y2_test_2 = train_test_split(X2, y2, test_size=0.33, random_state=42)  # 66.6-33.3\n",
    "X2_train_3, X2_test_3, y2_train_3, y2_test_3 = train_test_split(X2, y2, test_size=0.3, random_state=42)  # 70-30\n",
    "\n",
    "print('Random Subsample for DF1:')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X1_train_1, y1_train_1)\n",
    "    y_pred_1 = clf.predict(X1_test_1)\n",
    "    acc_1 = accuracy_score(y1_test_1, y_pred_1)\n",
    "\n",
    "    clf.fit(X1_train_2, y1_train_2)\n",
    "    y_pred_2 = clf.predict(X1_test_2)\n",
    "    acc_2 = accuracy_score(y1_test_2, y_pred_2)\n",
    "\n",
    "    clf.fit(X1_train_3, y1_train_3)\n",
    "    y_pred_3 = clf.predict(X1_test_3)\n",
    "    acc_3 = accuracy_score(y1_test_3, y_pred_3)\n",
    "\n",
    "    accuracy = (acc_1 + acc_2 + acc_3) / 3\n",
    "\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nRandom Subsample for DF2:')\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X2_train_1, y2_train_1)\n",
    "    y_pred_1 = clf.predict(X2_test_1)\n",
    "    acc_1 = accuracy_score(y2_test_1, y_pred_1)\n",
    "\n",
    "    clf.fit(X2_train_2, y2_train_2)\n",
    "    y_pred_2 = clf.predict(X2_test_2)\n",
    "    acc_2 = accuracy_score(y2_test_2, y_pred_2)\n",
    "\n",
    "    clf.fit(X2_train_3, y2_train_3)\n",
    "    y_pred_3 = clf.predict(X2_test_3)\n",
    "    acc_3 = accuracy_score(y2_test_3, y_pred_3)\n",
    "\n",
    "    accuracy = (acc_1 + acc_2 + acc_3) / 3\n",
    "\n",
    "    print('  ', f\"{name} Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) 5-Fold Cross-Validation \n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = ['accuracy']\n",
    "\n",
    "models = [KNeighborsClassifier(), GaussianNB(), DecisionTreeClassifier()]\n",
    "\n",
    "print('5-Fold CV for DF1:')\n",
    "for model in models:\n",
    "    result = list()\n",
    "    scores = cross_validate(model, X1, y1, cv=kf, scoring=scoring)\n",
    "\n",
    "    for value in scores:\n",
    "        v = str(value)\n",
    "        mean_score = scores[v].mean()\n",
    "        std_score = scores[v].std()\n",
    "        if (v == \"fit_time\" or v == \"score_time\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"{model} --> {mean_score:.2f} ± {std_score:.2f}\")\n",
    "\n",
    "print('\\n5-Fold CV for DF2:')\n",
    "for model in models:\n",
    "    result = list()\n",
    "    scores = cross_validate(model, X2, y2, cv=kf, scoring=scoring)\n",
    "\n",
    "    for value in scores:\n",
    "        v = str(value)\n",
    "        mean_score = scores[v].mean()\n",
    "        std_score = scores[v].std()\n",
    "        if (v == \"fit_time\" or v == \"score_time\"):\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"{model} --> {mean_score:.2f} ± {std_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e68970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.3 Results after scaling the values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.fit_transform(X2)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, stratify=y1, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2, random_state=42)\n",
    "\n",
    "print('After Scaling values for DF1: 80% Train - 20% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X1_test)\n",
    "    accuracy = accuracy_score(y1_test, y_pred)\n",
    "    print('  ',f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print('\\nAfter Scaling values for DF2: 80% Train - 20% Test')\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X2_train, y2_train)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X2_test)\n",
    "    accuracy = accuracy_score(y2_test, y_pred)\n",
    "    print('  ',f\"{name} Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
